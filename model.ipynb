{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b748d954",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medical-ai-overview",
   "metadata": {},
   "source": [
    "# Medical AI - Disease Detection from Medical Images\n",
    "\n",
    "This notebook implements a Convolutional Neural Network (CNN) for medical image classification.\n",
    "The model can detect diseases from X-ray, CT, or MRI images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-loader",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading and Preprocessing\n",
    "class MedicalImageDataLoader:\n",
    "    def __init__(self, image_size=(224, 224), batch_size=32):\n",
    "        self.image_size = image_size\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def load_data(self, data_path):\n",
    "        \"\"\"Load medical images from directory\"\"\"\n",
    "        datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            validation_split=0.2,\n",
    "            rotation_range=20,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            fill_mode='nearest'\n",
    "        )\n",
    "        \n",
    "        train_generator = datagen.flow_from_directory(\n",
    "            data_path,\n",
    "            target_size=self.image_size,\n",
    "            batch_size=self.batch_size,\n",
    "            class_mode='categorical',\n",
    "            subset='training'\n",
    "        )\n",
    "        \n",
    "        validation_generator = datagen.flow_from_directory(\n",
    "            data_path,\n",
    "            target_size=self.image_size,\n",
    "            batch_size=self.batch_size,\n",
    "            class_mode='categorical',\n",
    "            subset='validation'\n",
    "        )\n",
    "        \n",
    "        return train_generator, validation_generator\n",
    "    \n",
    "    def preprocess_single_image(self, image_path):\n",
    "        \"\"\"Preprocess a single image for prediction\"\"\"\n",
    "        img = tf.keras.preprocessing.image.load_img(\n",
    "            image_path, target_size=self.image_size\n",
    "        )\n",
    "        img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        img_array = img_array / 255.0\n",
    "        return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model-architecture",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Medical Image Classification Model\n",
    "class MedicalAIModel:\n",
    "    def __init__(self, num_classes, input_shape=(224, 224, 3)):\n",
    "        self.num_classes = num_classes\n",
    "        self.input_shape = input_shape\n",
    "        self.model = None\n",
    "    \n",
    "    def build_model(self):\n",
    "        \"\"\"Build CNN model for disease detection\"\"\"\n",
    "        model = models.Sequential([\n",
    "            # Convolutional Block 1\n",
    "            layers.Conv2D(32, (3, 3), activation='relu', \n",
    "                         input_shape=self.input_shape, padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.MaxPooling2D((2, 2)),\n",
    "            layers.Dropout(0.25),\n",
    "            \n",
    "            # Convolutional Block 2\n",
    "            layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.MaxPooling2D((2, 2)),\n",
    "            layers.Dropout(0.25),\n",
    "            \n",
    "            # Convolutional Block 3\n",
    "            layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.MaxPooling2D((2, 2)),\n",
    "            layers.Dropout(0.25),\n",
    "            \n",
    "            # Dense Layers\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(256, activation='relu'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dropout(0.5),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dropout(0.5),\n",
    "            layers.Dense(self.num_classes, activation='softmax')\n",
    "        ])\n",
    "        \n",
    "        self.model = model\n",
    "        return model\n",
    "    \n",
    "    def compile_model(self, learning_rate=0.001):\n",
    "        \"\"\"Compile the model with optimizer and loss\"\"\"\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "        self.model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy', tf.keras.metrics.AUC(), \n",
    "                    tf.keras.metrics.Precision(), \n",
    "                    tf.keras.metrics.Recall()]\n",
    "        )\n",
    "    \n",
    "    def train(self, train_data, validation_data, epochs=50):\n",
    "        \"\"\"Train the model\"\"\"\n",
    "        callbacks = [\n",
    "            tf.keras.callbacks.EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                patience=10,\n",
    "                restore_best_weights=True\n",
    "            ),\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                monitor='val_loss',\n",
    "                factor=0.5,\n",
    "                patience=5,\n",
    "                min_lr=1e-7\n",
    "            ),\n",
    "            tf.keras.callbacks.ModelCheckpoint(\n",
    "                'best_medical_model.h5',\n",
    "                monitor='val_accuracy',\n",
    "                save_best_only=True\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        history = self.model.fit(\n",
    "            train_data,\n",
    "            validation_data=validation_data,\n",
    "            epochs=epochs,\n",
    "            callbacks=callbacks\n",
    "        )\n",
    "        \n",
    "        return history\n",
    "    \n",
    "    def predict(self, image):\n",
    "        \"\"\"Make prediction on a single image\"\"\"\n",
    "        prediction = self.model.predict(image)\n",
    "        return prediction\n",
    "    \n",
    "    def save_model(self, filepath):\n",
    "        \"\"\"Save the model\"\"\"\n",
    "        self.model.save(filepath)\n",
    "    \n",
    "    def load_model(self, filepath):\n",
    "        \"\"\"Load a saved model\"\"\"\n",
    "        self.model = tf.keras.models.load_model(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "evaluation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation and Visualization\n",
    "class ModelEvaluator:\n",
    "    def __init__(self, model, class_names):\n",
    "        self.model = model\n",
    "        self.class_names = class_names\n",
    "    \n",
    "    def plot_training_history(self, history):\n",
    "        \"\"\"Plot training and validation metrics\"\"\"\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        \n",
    "        # Accuracy\n",
    "        axes[0, 0].plot(history.history['accuracy'], label='Training')\n",
    "        axes[0, 0].plot(history.history['val_accuracy'], label='Validation')\n",
    "        axes[0, 0].set_title('Model Accuracy')\n",
    "        axes[0, 0].set_xlabel('Epoch')\n",
    "        axes[0, 0].set_ylabel('Accuracy')\n",
    "        axes[0, 0].legend()\n",
    "        axes[0, 0].grid(True)\n",
    "        \n",
    "        # Loss\n",
    "        axes[0, 1].plot(history.history['loss'], label='Training')\n",
    "        axes[0, 1].plot(history.history['val_loss'], label='Validation')\n",
    "        axes[0, 1].set_title('Model Loss')\n",
    "        axes[0, 1].set_xlabel('Epoch')\n",
    "        axes[0, 1].set_ylabel('Loss')\n",
    "        axes[0, 1].legend()\n",
    "        axes[0, 1].grid(True)\n",
    "        \n",
    "        # AUC\n",
    "        if 'auc' in history.history:\n",
    "            axes[1, 0].plot(history.history['auc'], label='Training')\n",
    "            axes[1, 0].plot(history.history['val_auc'], label='Validation')\n",
    "            axes[1, 0].set_title('Model AUC')\n",
    "            axes[1, 0].set_xlabel('Epoch')\n",
    "            axes[1, 0].set_ylabel('AUC')\n",
    "            axes[1, 0].legend()\n",
    "            axes[1, 0].grid(True)\n",
    "        \n",
    "        # Precision\n",
    "        if 'precision' in history.history:\n",
    "            axes[1, 1].plot(history.history['precision'], label='Training')\n",
    "            axes[1, 1].plot(history.history['val_precision'], label='Validation')\n",
    "            axes[1, 1].set_title('Model Precision')\n",
    "            axes[1, 1].set_xlabel('Epoch')\n",
    "            axes[1, 1].set_ylabel('Precision')\n",
    "            axes[1, 1].legend()\n",
    "            axes[1, 1].grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('training_history.png')\n",
    "        plt.show()\n",
    "    \n",
    "    def evaluate_model(self, test_data):\n",
    "        \"\"\"Evaluate model on test data\"\"\"\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        \n",
    "        for images, labels in test_data:\n",
    "            predictions = self.model.predict(images)\n",
    "            y_pred.extend(np.argmax(predictions, axis=1))\n",
    "            y_true.extend(np.argmax(labels, axis=1))\n",
    "        \n",
    "        return y_true, y_pred\n",
    "    \n",
    "    def plot_confusion_matrix(self, y_true, y_pred):\n",
    "        \"\"\"Plot confusion matrix\"\"\"\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        \n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                   xticklabels=self.class_names,\n",
    "                   yticklabels=self.class_names)\n",
    "        plt.title('Confusion Matrix - Disease Classification')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('confusion_matrix.png')\n",
    "        plt.show()\n",
    "    \n",
    "    def generate_classification_report(self, y_true, y_pred):\n",
    "        \"\"\"Generate classification report\"\"\"\n",
    "        report = classification_report(y_true, y_pred, \n",
    "                                      target_names=self.class_names)\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(\"=\" * 60)\n",
    "        print(report)\n",
    "        return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "usage-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Usage\n",
    "# Note: Replace 'path/to/dataset' with your actual medical image dataset path\n",
    "# Expected directory structure:\n",
    "# dataset/\n",
    "#   class1/\n",
    "#     image1.jpg\n",
    "#     image2.jpg\n",
    "#   class2/\n",
    "#     image1.jpg\n",
    "#     image2.jpg\n",
    "\n",
    "# Initialize components\n",
    "# data_loader = MedicalImageDataLoader(image_size=(224, 224), batch_size=32)\n",
    "# train_data, val_data = data_loader.load_data('path/to/dataset')\n",
    "\n",
    "# Build and compile model\n",
    "# num_classes = len(train_data.class_indices)\n",
    "# medical_ai = MedicalAIModel(num_classes=num_classes)\n",
    "# medical_ai.build_model()\n",
    "# medical_ai.compile_model(learning_rate=0.001)\n",
    "\n",
    "# Train model\n",
    "# history = medical_ai.train(train_data, val_data, epochs=50)\n",
    "\n",
    "# Evaluate model\n",
    "# class_names = list(train_data.class_indices.keys())\n",
    "# evaluator = ModelEvaluator(medical_ai.model, class_names)\n",
    "# evaluator.plot_training_history(history)\n",
    "\n",
    "# Make predictions on test data\n",
    "# y_true, y_pred = evaluator.evaluate_model(val_data)\n",
    "# evaluator.plot_confusion_matrix(y_true, y_pred)\n",
    "# evaluator.generate_classification_report(y_true, y_pred)\n",
    "\n",
    "# Save model\n",
    "# medical_ai.save_model('medical_ai_model.h5')\n",
    "\n",
    "# Predict single image\n",
    "# image = data_loader.preprocess_single_image('path/to/test/image.jpg')\n",
    "# prediction = medical_ai.predict(image)\n",
    "# predicted_class = class_names[np.argmax(prediction)]\n",
    "# confidence = np.max(prediction) * 100\n",
    "# print(f'Predicted Disease: {predicted_class}')\n",
    "# print(f'Confidence: {confidence:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
